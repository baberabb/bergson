{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from contextlib import nullcontext\n",
    "from dataclasses import asdict\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset, DatasetDict, IterableDatasetDict, load_dataset\n",
    "from jaxtyping import Float\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import load_file, save_file\n",
    "from torch import Tensor\n",
    "from torch.profiler import (\n",
    "    ProfilerActivity,\n",
    "    profile,\n",
    "    record_function,\n",
    "    schedule,\n",
    "    tensorboard_trace_handler,\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, PreTrainedModel\n",
    "\n",
    "from bergson.data import DataConfig, IndexConfig, create_index, load_gradients, pad_and_tensor, tokenize\n",
    "from bergson.gradients import (\n",
    "    GradientProcessor,\n",
    ")\n",
    "from bergson.hessians.collector import EkfacCollector\n",
    "from bergson.hessians.logger import get_logger\n",
    "from bergson.hessians.utils import TensorDict\n",
    "from bergson.utils import assert_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load EKFAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekfac_path = \"\"\n",
    "\n",
    "# all paths inside ekfac_path\n",
    "world_size = len(os.listdir(ekfac_path + \"/activation_covariance_sharded\"))\n",
    "\n",
    "eigen_a_paths = [ekfac_path + f\"/activation_eigen_sharded/shard_{rank}.safetensors\" for rank in range(world_size)]\n",
    "eigen_a = [load_file(path, device=\"cuda\") for path in eigen_a_paths]\n",
    "\n",
    "eigen_g_paths = [ekfac_path + f\"/gradient_eigen_sharded/shard_{rank}.safetensors\" for rank in range(world_size)]\n",
    "eigen_g = [load_file(path, device=\"cuda\") for path in eigen_g_paths]\n",
    "\n",
    "lambda_factor_paths = [\n",
    "    ekfac_path + f\"/eigenvalue_correction_sharded/shard_{rank}.safetensors\" for rank in range(world_size)\n",
    "]\n",
    "lambda_factor = [load_file(path, device=\"cuda\") for path in lambda_factor_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekfac_path = \"/root/bergson-approx-unrolling/bergson/hessians/peft_fin_mis_fin/influence_results\"\n",
    "world_size = len(os.listdir(ekfac_path + \"/activation_covariance_sharded\"))\n",
    "lambda_factor_paths = [\n",
    "    ekfac_path + f\"/inverse_eigenvalue_correction_sharded/shard_{rank}.safetensors\" for rank in range(world_size)\n",
    "]\n",
    "lambda_factor = [load_file(path, device=\"cuda\") for path in lambda_factor_paths]\n",
    "lambda_factor_tensor = {}\n",
    "for k, v in lambda_factor[0].items():\n",
    "    lambda_factor_tensor[k] = torch.cat([lambda_factor[rank][k] for rank in range(world_size)], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.0.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.0.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.0.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.0.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.0.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.1.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.1.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.1.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.1.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.1.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.1.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.10.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.10.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.10.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.10.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.10.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.10.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.11.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.11.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.11.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.11.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.11.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.11.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.12.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.12.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.12.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.12.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.12.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.12.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.13.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.13.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.13.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.13.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.13.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.13.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.14.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.14.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.14.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.14.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.14.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.14.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.15.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.15.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.15.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.15.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.15.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.15.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.16.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.16.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.16.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.16.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.16.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.16.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.17.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.17.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.17.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.17.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.17.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.17.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.18.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.18.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.18.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.18.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.18.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.18.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.19.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.19.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.19.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.19.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.19.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.19.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.2.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.2.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.2.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.2.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.2.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.2.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.20.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.20.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.20.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.20.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.20.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.20.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.21.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.21.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.21.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.21.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.21.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.21.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.22.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.22.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.22.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.22.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.22.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.22.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.23.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.23.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.23.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.23.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.23.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.23.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.24.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.24.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.24.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.24.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.24.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.24.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.25.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.25.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.25.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.25.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.25.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.25.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.26.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.26.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.26.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.26.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.26.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.26.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.27.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.27.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.27.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.27.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.27.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.27.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.28.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.28.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.28.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.28.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.28.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.28.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.29.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.29.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.29.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.29.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.29.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.29.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.3.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.3.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.3.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.3.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.3.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.3.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.30.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.30.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.30.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.30.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.30.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.30.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.31.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.31.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.31.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.31.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.31.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.31.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.32.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.32.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.32.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.32.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.32.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.32.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.33.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.33.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.33.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.33.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.33.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.33.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.34.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.34.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.34.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.34.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.34.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.34.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.35.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.35.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.35.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.35.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.35.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.35.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.36.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.36.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.36.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.36.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.36.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.36.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.37.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.37.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.37.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.37.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.37.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.37.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.38.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.38.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.38.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.38.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.38.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.38.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.39.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.39.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.39.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.39.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.39.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.39.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.4.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.4.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.4.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.4.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.4.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.4.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.40.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.40.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.40.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.40.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.40.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.40.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.41.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.41.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.41.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.41.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.41.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.41.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.42.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.42.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.42.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.42.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.42.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.42.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.43.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.43.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.43.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.43.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.43.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.43.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.44.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.44.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.44.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.44.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.44.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.44.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.45.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.45.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.45.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.45.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.45.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.45.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.46.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.46.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.46.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.46.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.46.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.46.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.47.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.47.mlp.down_proj.lora_B.default 10.0 0.0001544952392578125 9.9375 10.0\n",
      "layers.47.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.47.mlp.gate_proj.lora_B.default 10.0 0.00018787384033203125 9.875 10.0\n",
      "layers.47.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.47.mlp.up_proj.lora_B.default 10.0 0.000469207763671875 9.75 10.0\n",
      "layers.5.mlp.down_proj.lora_A.default 10.0 0.00018787384033203125 9.875 10.0\n",
      "layers.5.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.5.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.5.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.5.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.5.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.6.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.6.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.6.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.6.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.6.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.6.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.7.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.7.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.7.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.7.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.7.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.7.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.8.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.8.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.8.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.8.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.8.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.8.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.9.mlp.down_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.9.mlp.down_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.9.mlp.gate_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.9.mlp.gate_proj.lora_B.default 10.0 0.0 10.0 10.0\n",
      "layers.9.mlp.up_proj.lora_A.default 10.0 0.0 10.0 10.0\n",
      "layers.9.mlp.up_proj.lora_B.default 10.0 0.0 10.0 10.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in lambda_factor_tensor.items():\n",
    "    print(k, v.mean().item(), v.std().item(), v.min().item(), v.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_gradients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n",
      "\u001b[32m      1\u001b[39m gradient_path = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m mmap = \u001b[43mload_gradients\u001b[49m(gradient_path)\n",
      "\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(gradient_path, \u001b[33m\"\u001b[39m\u001b[33minfo.json\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[32m      5\u001b[39m     info = json.load(f)\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'load_gradients' is not defined"
     ]
    }
   ],
   "source": [
    "gradient_path = \"\"\n",
    "\n",
    "mmap = load_gradients(gradient_path)\n",
    "with open(os.path.join(gradient_path, \"info.json\")) as f:\n",
    "    info = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply EKFAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
