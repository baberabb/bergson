{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from dataclasses import asdict\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset, DatasetDict, IterableDatasetDict, load_dataset, load_from_disk\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import load_file, save_file\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, PreTrainedModel\n",
    "\n",
    "from bergson.approx_unrolling.utils import TensorDict\n",
    "from bergson.data import DataConfig, IndexConfig, pad_and_tensor, tokenize\n",
    "from bergson.gradients import (\n",
    "    GradientProcessor,\n",
    ")\n",
    "from bergson.hessians.collector import EkfacCollector\n",
    "from bergson.utils import assert_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -1. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_batches_test(doc_lengths: list[int], N: int, workers: Optional[int] = None) -> list[list[list[int]]]:\n",
    "    \"\"\"\n",
    "    Modification of allocate_batches to return a flat list of batches for testing (instead of returning allocation[rank])\n",
    "    Allocate documents into batches that are then distributed evenly across\n",
    "    a fixed number of workers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_lengths : Sequence[int]\n",
    "        Length (in tokens) of each document.  The *i-th* document is referred to\n",
    "        internally by its index ``i``.\n",
    "    workers : int\n",
    "        Number of parallel workers ( 1 ≤ workers ≤ 8).\n",
    "    N : int\n",
    "        Hard memory budget per *batch*, expressed as\n",
    "        ``max(length in batch) * (# docs in batch) ≤ N``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[list[list[int]]]\n",
    "        ``allocation[w][b]`` is the list of document indices that belong to the\n",
    "        *b-th* batch assigned to worker ``w``.  Every worker receives the same\n",
    "        number of (non-empty) batches.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    AllocationError\n",
    "        If the three hard constraints cannot be satisfied.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    1.  **Per-batch cost constraint**:  Each batch is padded to the maximum\n",
    "        sequence length *inside that batch*, so its cost in “token × examples”\n",
    "        units is ``max_len_in_batch * batch_size``.  This must stay ≤ ``N``.\n",
    "    2.  **Bin-packing strategy**:  We use *first-fit decreasing* (FFD) to obtain\n",
    "        an initial near-minimal set of batches, then split some of the larger\n",
    "        batches (never increases cost) until\n",
    "\n",
    "            * every worker has at least one batch,\n",
    "            * the total number of batches is a multiple of ``workers``.\n",
    "\n",
    "        Because each split only lowers the cost of the two resulting batches,\n",
    "        the constraint in (1) remains satisfied throughout.\n",
    "    \"\"\"\n",
    "\n",
    "    if workers is None:\n",
    "        world_size = dist.get_world_size() if dist.is_initialized() else 1\n",
    "    else:\n",
    "        world_size = workers\n",
    "\n",
    "    if not doc_lengths:\n",
    "        raise RuntimeError(\"Empty document list.\")\n",
    "    if max(doc_lengths) > N:  # a single document would overflow any batch\n",
    "        raise RuntimeError(\"At least one document is too long for the budget N.\")\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 1) First-fit decreasing (FFD) bin packing under the cost function\n",
    "    #    cost(batch) = max_len_in_batch * len(batch)\n",
    "    # ---------------------------------------------------------------------\n",
    "    docs_sorted = sorted(enumerate(doc_lengths), key=lambda x: x[1], reverse=True)\n",
    "    batches: list[list[int]] = []  # holds document *indices*\n",
    "    batch_meta = []  # (max_len, size) for each batch\n",
    "\n",
    "    for idx, length in docs_sorted:\n",
    "        placed = False\n",
    "        for j, (mx, sz) in enumerate(batch_meta):\n",
    "            new_mx = max(mx, length)\n",
    "            new_sz = sz + 1\n",
    "            if new_mx * new_sz <= N:  # still fits\n",
    "                batches[j].append(idx)\n",
    "                batch_meta[j] = (new_mx, new_sz)\n",
    "                placed = True\n",
    "                break\n",
    "\n",
    "        if not placed:  # open a new batch\n",
    "            batches.append([idx])\n",
    "            batch_meta.append((length, 1))\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 2) Ensure every worker gets ≥ 1 batch\n",
    "    # ---------------------------------------------------------------------\n",
    "    if len(batches) < world_size:\n",
    "        # split the largest batches (by size) until we have ≥ workers batches\n",
    "        batches.sort(key=len, reverse=True)\n",
    "        while len(batches) < world_size:\n",
    "            big = batches.pop(0)  # take the current largest\n",
    "            if len(big) == 1:  # cannot split a singleton\n",
    "                raise RuntimeError(\"Not enough documents to give each worker at least one batch.\")\n",
    "            batches.append([big.pop()])  # move one doc into new batch\n",
    "            batches.append(big)  # put the remainder back\n",
    "            # preserve cost constraint automatically\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 3) Pad the number of batches to a multiple of `workers`\n",
    "    # ---------------------------------------------------------------------\n",
    "    k = -(-len(batches) // world_size)  # ceiling division\n",
    "    target_batches = world_size * k  # == k batches per worker\n",
    "\n",
    "    # Split arbitrary (non-singleton) batches until we reach the target\n",
    "    i = 0\n",
    "    while len(batches) < target_batches:\n",
    "        batch = batches[i % len(batches)]\n",
    "        if len(batch) == 1:\n",
    "            i += 1  # try another batch\n",
    "            continue\n",
    "        batches.append([batch.pop()])  # split off a singleton\n",
    "        i += 1\n",
    "\n",
    "    assert len(batches) == target_batches\n",
    "    assert all(max(doc_lengths[i] for i in batch) * len(batch) <= N for batch in batches)\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 4) Round-robin assignment to workers\n",
    "    # ---------------------------------------------------------------------\n",
    "    allocation: list[list[list[int]]] = [[] for _ in range(world_size)]\n",
    "    for b_idx, batch in enumerate(batches):\n",
    "        allocation[b_idx % world_size].append(batch)\n",
    "\n",
    "    # sanity: equal # of batches per worker\n",
    "    assert len({len(b) for b in allocation}) == 1\n",
    "    return allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/root/bergson-approx-unrolling/tests/ekfac_tests/test_files/pile_100_examples/ground_truth\"\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "cfg = IndexConfig(run_path=\"\")  # empty run path because we are not using it to save data\n",
    "cfg.model = \"EleutherAI/Pythia-14m\"\n",
    "cfg.precision = \"fp32\"\n",
    "cfg.revision = None\n",
    "cfg.fsdp = False\n",
    "cfg.normalizer = \"none\"\n",
    "cfg.fisher_fourth_root = False\n",
    "cfg.data = DataConfig(dataset=\"/root/bergson-approx-unrolling/tests/ekfac_tests/test_files/pile_100_examples\" + \"/data\")\n",
    "\n",
    "data_str = cfg.data.dataset\n",
    "\n",
    "# save cfg\n",
    "with open(os.path.join(test_path, \"index_config.json\"), \"w\") as f:\n",
    "    json.dump(asdict(cfg), f, indent=4)\n",
    "\n",
    "\n",
    "workers = 8  # simulating n workers, but we will run on a single GPU to get ground truth\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "match cfg.precision:\n",
    "    case \"bf16\":\n",
    "        dtype = torch.bfloat16\n",
    "    case \"fp16\":\n",
    "        dtype = torch.float16\n",
    "    case \"fp32\":\n",
    "        dtype = torch.float32\n",
    "    case \"int4\" | \"int8\":\n",
    "        dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "    case other:\n",
    "        raise ValueError(f\"Unsupported precision: {other}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_name = \"layers.0.mlp.dense_4h_to_h\"  # for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    cfg.model,\n",
    "    device_map=\"cuda\",\n",
    "    quantization_config=(\n",
    "        BitsAndBytesConfig(\n",
    "            load_in_4bit=cfg.precision == \"int4\",\n",
    "            load_in_8bit=cfg.precision == \"int8\",\n",
    "            bnb_4bit_compute_dtype=dtype,\n",
    "            bnb_4bit_quant_storage=dtype,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "        )\n",
    "        if cfg.precision in (\"int4\", \"int8\")\n",
    "        else None\n",
    "    ),\n",
    "    torch_dtype=dtype,\n",
    "    revision=cfg.revision,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_str = cfg.data.dataset\n",
    "if data_str.endswith(\".csv\"):\n",
    "    ds = assert_type(Dataset, Dataset.from_csv(data_str))\n",
    "elif data_str.endswith(\".json\") or data_str.endswith(\".jsonl\"):\n",
    "    ds = assert_type(Dataset, Dataset.from_json(data_str))\n",
    "else:\n",
    "    try:\n",
    "        ds = load_dataset(data_str, split=\"train\", streaming=cfg.streaming)\n",
    "\n",
    "        if isinstance(ds, DatasetDict) or isinstance(ds, IterableDatasetDict):\n",
    "            raise NotImplementedError(\"DatasetDicts and IterableDatasetDicts are not supported.\")\n",
    "    except ValueError as e:\n",
    "        # Automatically use load_from_disk if appropriate\n",
    "        if \"load_from_disk\" in str(e):\n",
    "            ds = Dataset.load_from_disk(data_str, keep_in_memory=False)\n",
    "        else:\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(ds, Dataset)  # pleasing the typechecker\n",
    "remove_columns = ds.column_names if cfg.drop_columns else None\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model, model_max_length=cfg.token_batch_size, revision=cfg.revision)\n",
    "\n",
    "\n",
    "ds = ds.map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    fn_kwargs=dict(args=cfg.data, tokenizer=tokenizer),\n",
    "    remove_columns=remove_columns,\n",
    ")\n",
    "\n",
    "data = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_world = allocate_batches_test(doc_lengths=ds[\"length\"], N=cfg.token_batch_size, workers=workers)\n",
    "assert len(batches_world) == workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_modules = None\n",
    "normalizers = {}\n",
    "\n",
    "processor = GradientProcessor(\n",
    "    normalizers=normalizers,\n",
    "    fisher_fourth_root=cfg.fisher_fourth_root,\n",
    "    projection_dim=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute activation and gradient covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_test_path = os.path.join(test_path, \"covariances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covariance(rank: int, activation_covariances={}, gradient_covariances={}):\n",
    "    total_processed = 0\n",
    "    batches = batches_world[rank]\n",
    "\n",
    "    loss_list = []\n",
    "\n",
    "    def callback_activation(name: str, a: torch.Tensor):\n",
    "        activation_covariance = activation_covariances.get(name, None)  # Our stored slice\n",
    "\n",
    "        a = a.reshape(-1, a.shape[-1])  # [N*S, O]\n",
    "        if name == debug_name:\n",
    "            print(a[0, 0])\n",
    "        update = a.mT @ a\n",
    "        if name == debug_name:\n",
    "            print(update[0, 0])\n",
    "        if activation_covariance is None:\n",
    "            activation_covariances[name] = update\n",
    "\n",
    "        else:\n",
    "            # Add it to our permanently stored slice\n",
    "            activation_covariance.add_(update)\n",
    "\n",
    "    def callback_gradient(name: str, g: torch.Tensor):\n",
    "        gradient_covariance = gradient_covariances.get(name, None)\n",
    "\n",
    "        g = g.reshape(-1, g.shape[-1])  # [N*S, O]\n",
    "        update = g.mT @ g\n",
    "\n",
    "        if gradient_covariance is None:\n",
    "            gradient_covariances[name] = update\n",
    "        else:\n",
    "            gradient_covariance.add_(update)\n",
    "\n",
    "    collector = EkfacCollector(\n",
    "        model.base_model,\n",
    "        closure=callback_gradient,\n",
    "        processor=processor,\n",
    "        target_modules=target_modules,\n",
    "        fwd_closure=callback_activation,\n",
    "    )\n",
    "    for sl in tqdm(batches):\n",
    "        batch = data[sl]\n",
    "        x, y = pad_and_tensor(\n",
    "            batch[\"input_ids\"],  # type: ignore\n",
    "            labels=batch.get(\"labels\"),  # type: ignore\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        total_processed += x.numel()\n",
    "\n",
    "        with collector:\n",
    "            logits = model(x).logits\n",
    "            losses = F.cross_entropy(\n",
    "                logits[:, :-1].reshape(-1, logits.size(-1)),\n",
    "                y[:, 1:].flatten(),\n",
    "                reduction=\"none\",\n",
    "            ).reshape_as(y[:, 1:])\n",
    "\n",
    "            masks = y[:, 1:] != -100\n",
    "            denoms = masks.sum(dim=1, dtype=logits.dtype)\n",
    "            losses = losses.sum(1).div(denoms)\n",
    "\n",
    "            losses.mean().backward()\n",
    "\n",
    "            loss_list.append(losses.detach().cpu())\n",
    "            model.zero_grad()\n",
    "\n",
    "    return {\"losses\": loss_list, \"total_processed_rank\": total_processed}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf91eec296ad4e83b1675ffd88cea888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1472, device='cuda:0')\n",
      "tensor(228.2182, device='cuda:0')\n",
      "tensor(-0.0817, device='cuda:0')\n",
      "tensor(249.5335, device='cuda:0')\n",
      "Rank 0 processed 14880 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61dca0cff2a4e5bb2feab61c7e087ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1252, device='cuda:0')\n",
      "tensor(281.4669, device='cuda:0')\n",
      "tensor(-0.1697, device='cuda:0')\n",
      "tensor(268.9439, device='cuda:0')\n",
      "Rank 1 processed 16109 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bd5498625e44588b347a9c0e821e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1698, device='cuda:0')\n",
      "tensor(145.3147, device='cuda:0')\n",
      "tensor(0.1371, device='cuda:0')\n",
      "tensor(268.7294, device='cuda:0')\n",
      "Rank 2 processed 11827 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb47abdb7f6433199b12a346dea9ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0746, device='cuda:0')\n",
      "tensor(85.5227, device='cuda:0')\n",
      "tensor(0.0257, device='cuda:0')\n",
      "tensor(263.4775, device='cuda:0')\n",
      "Rank 3 processed 11518 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d98f0f3b39642f18fed6a727cabbe2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1678, device='cuda:0')\n",
      "tensor(109.1089, device='cuda:0')\n",
      "tensor(-0.1621, device='cuda:0')\n",
      "tensor(301.1600, device='cuda:0')\n",
      "Rank 4 processed 10873 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de41bcfc7ad44bd88b7ae2c10607b8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0817, device='cuda:0')\n",
      "tensor(264.0168, device='cuda:0')\n",
      "tensor(-0.1667, device='cuda:0')\n",
      "tensor(227.9193, device='cuda:0')\n",
      "Rank 5 processed 15216 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f7f9c4575c4759961fe85dbf715c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1371, device='cuda:0')\n",
      "tensor(237.6581, device='cuda:0')\n",
      "tensor(0.0290, device='cuda:0')\n",
      "tensor(105.6101, device='cuda:0')\n",
      "Rank 6 processed 9965 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54fa5f787ea4a1380db6bd9c38f3ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1503, device='cuda:0')\n",
      "tensor(289.1858, device='cuda:0')\n",
      "tensor(-0.1390, device='cuda:0')\n",
      "tensor(118.7222, device='cuda:0')\n",
      "Rank 7 processed 11038 tokens.\n"
     ]
    }
   ],
   "source": [
    "total_processed_global = 0\n",
    "for rank in range(workers):\n",
    "    covariance_test_path_rank = os.path.join(covariance_test_path, f\"rank_{rank}\")\n",
    "    os.makedirs(covariance_test_path_rank, exist_ok=True)\n",
    "\n",
    "    activation_covariances = {}\n",
    "    gradient_covariances = {}\n",
    "    d = compute_covariance(\n",
    "        rank=rank, activation_covariances=activation_covariances, gradient_covariances=gradient_covariances\n",
    "    )\n",
    "\n",
    "    save_file(activation_covariances, os.path.join(covariance_test_path_rank, \"activation_covariance.safetensors\"))\n",
    "    save_file(gradient_covariances, os.path.join(covariance_test_path_rank, \"gradient_covariance.safetensors\"))\n",
    "    with open(os.path.join(covariance_test_path_rank, \"stats.json\"), \"w\") as f:\n",
    "        json.dump({\"total_processed_rank\": d[\"total_processed_rank\"]}, f, indent=4)\n",
    "        print(f\"Rank {rank} processed {d['total_processed_rank']} tokens.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results from all ranks\n",
    "activation_covariances = TensorDict({})\n",
    "gradient_covariances = TensorDict({})\n",
    "total_processed_global = 0\n",
    "loss_list = []\n",
    "\n",
    "for rank in range(workers):\n",
    "    covariance_test_path_rank = os.path.join(covariance_test_path, f\"rank_{rank}\")\n",
    "\n",
    "    with open(os.path.join(covariance_test_path_rank, \"stats.json\"), \"r\") as f:\n",
    "        d = json.load(f)\n",
    "        total_processed_global += d[\"total_processed_rank\"]\n",
    "\n",
    "    # TensorDict wrapper to simplify tensor operations over dicts of tensors\n",
    "    activation_covariances_rank = TensorDict(\n",
    "        load_file(os.path.join(covariance_test_path_rank, \"activation_covariance.safetensors\"))\n",
    "    ).to(device)\n",
    "\n",
    "    gradient_covariances_rank = TensorDict(\n",
    "        load_file(os.path.join(covariance_test_path_rank, \"gradient_covariance.safetensors\"))\n",
    "    ).to(device)\n",
    "\n",
    "    if not activation_covariances:\n",
    "        activation_covariances = activation_covariances_rank\n",
    "    else:\n",
    "        activation_covariances = activation_covariances + activation_covariances_rank\n",
    "\n",
    "    if not gradient_covariances:\n",
    "        gradient_covariances = gradient_covariances_rank\n",
    "    else:\n",
    "        gradient_covariances = gradient_covariances + (gradient_covariances_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3444.5876, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_covariances[debug_name][0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global processed 101426 tokens.\n"
     ]
    }
   ],
   "source": [
    "save_file(activation_covariances.to_dict(), os.path.join(covariance_test_path, \"activation_covariance.safetensors\"))\n",
    "save_file(gradient_covariances.to_dict(), os.path.join(covariance_test_path, \"gradient_covariance.safetensors\"))\n",
    "with open(os.path.join(covariance_test_path, \"stats.json\"), \"w\") as f:\n",
    "    json.dump({\"total_processed_global\": total_processed_global}, f, indent=4)\n",
    "    print(f\"Global processed {total_processed_global} tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, eigh will be done in float64!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvectors_test_path = os.path.join(test_path, \"eigenvectors\")\n",
    "os.makedirs(eigenvectors_test_path, exist_ok=True)\n",
    "\n",
    "eigenvectors_activations = {}\n",
    "eigenvectors_gradients = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load activation and gradient covariance, and total processed\n",
    "with open(os.path.join(covariance_test_path, \"stats.json\"), \"r\") as f:\n",
    "    d = json.load(f)\n",
    "    total_processed_global = d[\"total_processed_global\"]\n",
    "\n",
    "activation_covariances = load_file(os.path.join(covariance_test_path, \"activation_covariance.safetensors\"))\n",
    "gradient_covariances = load_file(os.path.join(covariance_test_path, \"gradient_covariance.safetensors\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use run_path to see if everything is correct from 3. and errors don't propagate\n",
    "# covariance_a_run_path = \"/root/bergson-approx-unrolling/tests/ekfac_tests/test_files/pile_100_examples/run/influence_results/activation_covariance_sharded/shard_0.safetensors\"\n",
    "# covariance_g_run_path = \"/root/bergson-approx-unrolling/tests/ekfac_tests/test_files/pile_100_examples/run/influence_results/gradient_covariance_sharded/shard_0.safetensors\"\n",
    "# activation_covariances = load_file(covariance_a_run_path)\n",
    "# gradient_covariances = load_file(covariance_g_run_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.mlp.dense_4h_to_h tensor(-0.7598, device='cuda:0', dtype=torch.float64) tensor(11.3137, device='cuda:0', dtype=torch.float64)\n",
      "layers.0.mlp.dense_h_to_4h tensor(-11.6196, device='cuda:0', dtype=torch.float64) tensor(2.9680, device='cuda:0', dtype=torch.float64)\n",
      "layers.1.mlp.dense_4h_to_h tensor(24.9510, device='cuda:0', dtype=torch.float64) tensor(-11.3137, device='cuda:0', dtype=torch.float64)\n",
      "layers.1.mlp.dense_h_to_4h tensor(13.0856, device='cuda:0', dtype=torch.float64) tensor(7.6671, device='cuda:0', dtype=torch.float64)\n",
      "layers.2.mlp.dense_4h_to_h tensor(5.2933, device='cuda:0', dtype=torch.float64) tensor(-11.3137, device='cuda:0', dtype=torch.float64)\n",
      "layers.2.mlp.dense_h_to_4h tensor(12.3074, device='cuda:0', dtype=torch.float64) tensor(5.0213, device='cuda:0', dtype=torch.float64)\n",
      "layers.3.mlp.dense_4h_to_h tensor(17.0578, device='cuda:0', dtype=torch.float64) tensor(11.3137, device='cuda:0', dtype=torch.float64)\n",
      "layers.3.mlp.dense_h_to_4h tensor(-13.9615, device='cuda:0', dtype=torch.float64) tensor(31.0923, device='cuda:0', dtype=torch.float64)\n",
      "layers.4.mlp.dense_4h_to_h tensor(-10.4965, device='cuda:0', dtype=torch.float64) tensor(-11.3137, device='cuda:0', dtype=torch.float64)\n",
      "layers.4.mlp.dense_h_to_4h tensor(-11.2878, device='cuda:0', dtype=torch.float64) tensor(0.0574, device='cuda:0', dtype=torch.float64)\n",
      "layers.5.mlp.dense_4h_to_h tensor(21.8138, device='cuda:0', dtype=torch.float64) tensor(-11.3137, device='cuda:0', dtype=torch.float64)\n",
      "layers.5.mlp.dense_h_to_4h tensor(-12.8444, device='cuda:0', dtype=torch.float64) tensor(-16.9980, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for name in activation_covariances.keys():\n",
    "    a = activation_covariances[name].to(dtype=torch.float64, device=device)\n",
    "    g = gradient_covariances[name].to(dtype=torch.float64, device=device)\n",
    "    a = (a + a.T).div(2)\n",
    "    g = (g + g.T).div(2)\n",
    "    a.div_(total_processed_global)\n",
    "    g.div_(total_processed_global)\n",
    "\n",
    "    eigenvalues_a, eigenvectors_a = torch.linalg.eigh(a)\n",
    "    eigenvalues_g, eigenvectors_g = torch.linalg.eigh(g)\n",
    "    print(name, eigenvectors_a.sum(), eigenvectors_g.sum())\n",
    "    eigenvectors_activations[name] = eigenvectors_a.to(dtype=dtype).contiguous()\n",
    "    eigenvectors_gradients[name] = eigenvectors_g.to(dtype=dtype).contiguous()\n",
    "\n",
    "save_file(eigenvectors_activations, os.path.join(eigenvectors_test_path, \"eigenvectors_activations.safetensors\"))\n",
    "save_file(eigenvectors_gradients, os.path.join(eigenvectors_test_path, \"eigenvectors_gradients.safetensors\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute eigenvaluecorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalue_correction_test_path = os.path.join(test_path, \"eigenvalue_corrections\")\n",
    "os.makedirs(eigenvalue_correction_test_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load eigenvectors\n",
    "eigenvectors_activations = load_file(os.path.join(eigenvectors_test_path, \"eigenvectors_activations.safetensors\"))\n",
    "eigenvectors_gradients = load_file(os.path.join(eigenvectors_test_path, \"eigenvectors_gradients.safetensors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load eigenvectors from run\n",
    "eigenvectors_activations_run_path = \"/root/bergson-approx-unrolling/tests/ekfac_tests/test_files/pile_100_examples/run/influence_results/activation_eigen_sharded\"\n",
    "\n",
    "world_size = len(os.listdir(eigenvectors_activations_run_path))  # number of shards\n",
    "# load run eigenvectors shards and concatenate them\n",
    "run_eigenvectors_shards = [\n",
    "    os.path.join(eigenvectors_activations_run_path, f\"shard_{rank}.safetensors\") for rank in range(world_size)\n",
    "]\n",
    "run_eigenvectors_list = [(load_file(shard)) for shard in run_eigenvectors_shards]\n",
    "run_eigenvectors = {}\n",
    "for k, v in run_eigenvectors_list[0].items():\n",
    "    run_eigenvectors[k] = torch.cat([shard[k] for shard in run_eigenvectors_list], dim=0)\n",
    "\n",
    "eigenvectors_activations = TensorDict(run_eigenvectors)\n",
    "\n",
    "\n",
    "eigenvectors_gradients_run_path = \"/root/bergson-approx-unrolling/tests/ekfac_tests/test_files/pile_100_examples/run/influence_results/gradient_eigen_sharded\"\n",
    "\n",
    "world_size = len(os.listdir(eigenvectors_gradients_run_path))  # number of shards\n",
    "# load run eigenvectors shards and concatenate them\n",
    "run_eigenvectors_shards = [\n",
    "    os.path.join(eigenvectors_gradients_run_path, f\"shard_{rank}.safetensors\") for rank in range(world_size)\n",
    "]\n",
    "run_eigenvectors_list = [(load_file(shard)) for shard in run_eigenvectors_shards]\n",
    "run_eigenvectors = {}\n",
    "for k, v in run_eigenvectors_list[0].items():\n",
    "    run_eigenvectors[k] = torch.cat([shard[k] for shard in run_eigenvectors_list], dim=0)\n",
    "\n",
    "eigenvectors_gradients = TensorDict(run_eigenvectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict({'layers.0.mlp.dense_4h_to_h': torch.Size([512, 512]), 'layers.0.mlp.dense_h_to_4h': torch.Size([128, 128]), 'layers.1.mlp.dense_4h_to_h': torch.Size([512, 512]), 'layers.1.mlp.dense_h_to_4h': torch.Size([128, 128]), 'layers.2.mlp.dense_4h_to_h': torch.Size([512, 512]), 'layers.2.mlp.dense_h_to_4h': torch.Size([128, 128]), 'layers.3.mlp.dense_4h_to_h': torch.Size([512, 512]), 'layers.3.mlp.dense_h_to_4h': torch.Size([128, 128]), 'layers.4.mlp.dense_4h_to_h': torch.Size([512, 512]), 'layers.4.mlp.dense_h_to_4h': torch.Size([128, 128]), 'layers.5.mlp.dense_4h_to_h': torch.Size([512, 512]), 'layers.5.mlp.dense_h_to_4h': torch.Size([128, 128])})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors_activations.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict({'layers.0.mlp.dense_4h_to_h': torch.Size([128, 128]), 'layers.0.mlp.dense_h_to_4h': torch.Size([512, 512]), 'layers.1.mlp.dense_4h_to_h': torch.Size([128, 128]), 'layers.1.mlp.dense_h_to_4h': torch.Size([512, 512]), 'layers.2.mlp.dense_4h_to_h': torch.Size([128, 128]), 'layers.2.mlp.dense_h_to_4h': torch.Size([512, 512]), 'layers.3.mlp.dense_4h_to_h': torch.Size([128, 128]), 'layers.3.mlp.dense_h_to_4h': torch.Size([512, 512]), 'layers.4.mlp.dense_4h_to_h': torch.Size([128, 128]), 'layers.4.mlp.dense_h_to_4h': torch.Size([512, 512]), 'layers.5.mlp.dense_4h_to_h': torch.Size([128, 128]), 'layers.5.mlp.dense_h_to_4h': torch.Size([512, 512])})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors_gradients.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalue_corrections = {}\n",
    "activation_cache = {}\n",
    "\n",
    "\n",
    "# only for debugging\n",
    "gradient_cache = {}\n",
    "pseudo_grad_cache = {}\n",
    "transformed_activation_cache = {}\n",
    "key_debug = \"layers.0.mlp.dense_h_to_4h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eigenvalue_correction(\n",
    "    rank: int,\n",
    "    eigenvalue_corrections,\n",
    "    eigenvectors_activations=eigenvectors_activations,\n",
    "    eigenvectors_gradients=eigenvectors_gradients,\n",
    "):\n",
    "    total_processed = 0\n",
    "    batches = batches_world[rank]\n",
    "    transformed_activation_cache = {}\n",
    "\n",
    "    def callback_activation(name: str, a: torch.Tensor):\n",
    "        a = a.reshape(-1, a.shape[-1])\n",
    "        # a = torch.ones_like(a)  # for debugging, pretend all activations are 1\n",
    "        activation = a\n",
    "        activation_cache[name] = activation\n",
    "\n",
    "    def callback_gradient(name: str, g: torch.Tensor):\n",
    "        eigenvector_a = eigenvectors_activations[name].to(device=device)\n",
    "        eigenvector_g = eigenvectors_gradients[name].to(device=device)\n",
    "\n",
    "        g = g.reshape(-1, g.shape[-1])  # [N*S, O]\n",
    "        # g = torch.ones_like(g)  # for debugging, pretend all gradients are 1\n",
    "        if name == debug_name:\n",
    "            gradient_cache[name] = g\n",
    "        gradient = torch.einsum(\"B I, B O -> B O I\", activation_cache[name], g)\n",
    "        gradient = torch.einsum(\" B O I, I J -> B O J \", gradient, eigenvector_a)\n",
    "        gradient = torch.einsum(\" O P, B O J -> B P J \", eigenvector_g, gradient)\n",
    "        gradient = gradient**2\n",
    "        correction = gradient.sum(dim=0)\n",
    "\n",
    "        if name not in eigenvalue_corrections:\n",
    "            eigenvalue_corrections[name] = correction\n",
    "        else:\n",
    "            eigenvalue_corrections[name].add_(correction)\n",
    "\n",
    "    collector = EkfacCollector(\n",
    "        model.base_model,\n",
    "        closure=callback_gradient,\n",
    "        processor=processor,\n",
    "        target_modules=target_modules,\n",
    "        fwd_closure=callback_activation,\n",
    "    )\n",
    "    for sl in tqdm(batches):\n",
    "        batch = data[sl]\n",
    "        x, y = pad_and_tensor(\n",
    "            batch[\"input_ids\"],  # type: ignore\n",
    "            labels=batch.get(\"labels\"),  # type: ignore\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        total_processed += x.numel()\n",
    "\n",
    "        with collector:\n",
    "            logits = model(x).logits\n",
    "            losses = F.cross_entropy(\n",
    "                logits[:, :-1].reshape(-1, logits.size(-1)),\n",
    "                y[:, 1:].flatten(),\n",
    "                reduction=\"none\",\n",
    "            ).reshape_as(y[:, 1:])\n",
    "\n",
    "            masks = y[:, 1:] != -100\n",
    "\n",
    "            denoms = masks.sum(dim=1, dtype=logits.dtype)\n",
    "            losses = losses.sum(1).div(denoms)\n",
    "\n",
    "            losses.mean().backward()\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "    return {\"losses\": loss_list, \"total_processed_rank\": total_processed}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_cache_amortized = {}\n",
    "\n",
    "\n",
    "def compute_eigenvalue_correction_amortized(\n",
    "    rank: int,\n",
    "    eigenvalue_corrections,\n",
    "    eigenvectors_activations=eigenvectors_activations,\n",
    "    eigenvectors_gradients=eigenvectors_gradients,\n",
    "):\n",
    "    total_processed = 0\n",
    "    batches = batches_world[rank]\n",
    "\n",
    "    def callback_activation(name: str, a: torch.Tensor):\n",
    "        a = a.reshape(-1, a.shape[-1])\n",
    "        # a = torch.ones_like(a)  # for debugging, pretend all activations are 1\n",
    "        activation = a\n",
    "        activation_cache[name] = activation\n",
    "\n",
    "    def callback_gradient(name: str, g: torch.Tensor):\n",
    "        eigenvector_a = eigenvectors_activations[name].to(device=device)\n",
    "        eigenvector_g = eigenvectors_gradients[name].to(device=device)\n",
    "        g = g.reshape(-1, g.shape[-1])  # [N*S, O]\n",
    "        # g = torch.ones_like(g)  # for debugging, pretend all gradients are 1\n",
    "\n",
    "        a_transformed = torch.einsum(\" B I, I J -> B J \", activation_cache[name], eigenvector_a)\n",
    "        g_transformed = torch.einsum(\" O P, B O -> B P \", eigenvector_g, g)\n",
    "        correction = torch.einsum(\" B I, B O -> O I\", a_transformed**2, g_transformed**2).contiguous()\n",
    "\n",
    "        if name == debug_name:\n",
    "            gradient_cache_amortized[name] = g\n",
    "        if name not in eigenvalue_corrections:\n",
    "            eigenvalue_corrections[name] = correction\n",
    "        else:\n",
    "            eigenvalue_corrections[name].add_(correction)\n",
    "\n",
    "    collector = EkfacCollector(\n",
    "        model.base_model,\n",
    "        closure=callback_gradient,\n",
    "        processor=processor,\n",
    "        target_modules=target_modules,\n",
    "        fwd_closure=callback_activation,\n",
    "    )\n",
    "    for sl in tqdm(batches):\n",
    "        batch = data[sl]\n",
    "        x, y = pad_and_tensor(\n",
    "            batch[\"input_ids\"],  # type: ignore\n",
    "            labels=batch.get(\"labels\"),  # type: ignore\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        total_processed += x.numel()\n",
    "\n",
    "        with collector:\n",
    "            logits = model(x).logits\n",
    "            losses = F.cross_entropy(\n",
    "                logits[:, :-1].reshape(-1, logits.size(-1)),\n",
    "                y[:, 1:].flatten(),\n",
    "                reduction=\"none\",\n",
    "            ).reshape_as(y[:, 1:])\n",
    "\n",
    "            masks = y[:, 1:] != -100\n",
    "\n",
    "            denoms = masks.sum(dim=1, dtype=logits.dtype)\n",
    "            losses = losses.sum(1).div(denoms)\n",
    "\n",
    "            losses.mean().backward()\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "    return {\"losses\": loss_list, \"total_processed_rank\": total_processed}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5942321c6dee4af9a6a9ae365ff719d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eigenvalue_corrections_amortized = {}\n",
    "d = compute_eigenvalue_correction_amortized(\n",
    "    rank=0,\n",
    "    eigenvalue_corrections=eigenvalue_corrections_amortized,\n",
    "    eigenvectors_activations=eigenvectors_activations,\n",
    "    eigenvectors_gradients=eigenvectors_gradients,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10346b2e92f34452be28024a4fbbd7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eigenvalue_corrections = {}\n",
    "\n",
    "d = compute_eigenvalue_correction(\n",
    "    rank=0,\n",
    "    eigenvalue_corrections=eigenvalue_corrections,\n",
    "    eigenvectors_activations=eigenvectors_activations,\n",
    "    eigenvectors_gradients=eigenvectors_gradients,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict({'layers.0.mlp.dense_4h_to_h': True})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorDict(gradient_cache).allclose(TensorDict(gradient_cache_amortized), rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict({'layers.5.mlp.dense_4h_to_h': True, 'layers.5.mlp.dense_h_to_4h': True, 'layers.4.mlp.dense_4h_to_h': True, 'layers.4.mlp.dense_h_to_4h': True, 'layers.3.mlp.dense_4h_to_h': True, 'layers.3.mlp.dense_h_to_4h': True, 'layers.2.mlp.dense_4h_to_h': True, 'layers.2.mlp.dense_h_to_4h': True, 'layers.1.mlp.dense_4h_to_h': True, 'layers.1.mlp.dense_h_to_4h': True, 'layers.0.mlp.dense_4h_to_h': True, 'layers.0.mlp.dense_h_to_4h': True})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorDict(eigenvalue_corrections).allclose(TensorDict(eigenvalue_corrections_amortized), rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e9c6656455436da010288d48a0ab0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.271848678588867\n",
      "4.119211673736572\n",
      "13.643840789794922\n",
      "14.622827529907227\n",
      "37.2396240234375\n",
      "72.9457778930664\n",
      "128.28128051757812\n",
      "112.6466064453125\n",
      "157.8490447998047\n",
      "140.68585205078125\n",
      "285.36260986328125\n",
      "tensor(1114.4866, device='cuda:0')\n",
      "136.58180236816406\n",
      "0.7740920782089233\n",
      "0.7610242366790771\n",
      "0.8301278948783875\n",
      "1.2057312726974487\n",
      "1.910771369934082\n",
      "4.466953277587891\n",
      "7.405303478240967\n",
      "6.048692226409912\n",
      "6.640722274780273\n",
      "6.148662567138672\n",
      "12.394901275634766\n",
      "tensor(419.1560, device='cuda:0')\n",
      "5.693317413330078\n",
      "Rank 0 processed 14880 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4add83d4d53a4bf9aafa8af32dfab15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0222883224487305\n",
      "4.762729167938232\n",
      "21.461706161499023\n",
      "21.423444747924805\n",
      "36.49967956542969\n",
      "55.056880950927734\n",
      "87.11467742919922\n",
      "44.95179748535156\n",
      "63.931854248046875\n",
      "48.53266906738281\n",
      "112.57388305664062\n",
      "tensor(849.7523, device='cuda:0')\n",
      "53.709285736083984\n",
      "0.6929242014884949\n",
      "0.6930639147758484\n",
      "0.7596778869628906\n",
      "1.1904324293136597\n",
      "1.9332486391067505\n",
      "4.441174507141113\n",
      "6.9858832359313965\n",
      "6.293508052825928\n",
      "7.229989051818848\n",
      "6.559919357299805\n",
      "12.27967643737793\n",
      "tensor(501.3336, device='cuda:0')\n",
      "6.075558662414551\n",
      "Rank 1 processed 16109 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736bf1a1910a4536b2b144168a77a3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98952317237854\n",
      "1.938016653060913\n",
      "4.428705215454102\n",
      "5.097169876098633\n",
      "7.534078598022461\n",
      "13.7261962890625\n",
      "24.131444931030273\n",
      "17.202289581298828\n",
      "19.817184448242188\n",
      "18.428916931152344\n",
      "40.528072357177734\n",
      "tensor(599.0623, device='cuda:0')\n",
      "18.35589599609375\n",
      "0.7342566251754761\n",
      "0.7232117652893066\n",
      "0.8431563377380371\n",
      "1.3015427589416504\n",
      "2.0450057983398438\n",
      "4.810928821563721\n",
      "6.991988182067871\n",
      "6.5149054527282715\n",
      "6.734266757965088\n",
      "6.144947052001953\n",
      "12.152721405029297\n",
      "tensor(493.0748, device='cuda:0')\n",
      "5.7992730140686035\n",
      "Rank 2 processed 11827 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe26c4b494314d519b688b19b26f250e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4023044109344482\n",
      "1.4839907884597778\n",
      "1.6001923084259033\n",
      "3.393977642059326\n",
      "6.485110759735107\n",
      "11.972146034240723\n",
      "22.947336196899414\n",
      "20.52071762084961\n",
      "24.358835220336914\n",
      "24.215211868286133\n",
      "53.665504455566406\n",
      "tensor(655.5424, device='cuda:0')\n",
      "24.58123016357422\n",
      "0.8604382872581482\n",
      "0.8476861715316772\n",
      "0.9706109166145325\n",
      "1.6216562986373901\n",
      "2.6466331481933594\n",
      "7.45058536529541\n",
      "10.226812362670898\n",
      "9.48196029663086\n",
      "9.386226654052734\n",
      "9.30970573425293\n",
      "18.06763458251953\n",
      "tensor(523.4388, device='cuda:0')\n",
      "8.561155319213867\n",
      "Rank 3 processed 11518 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a79b56598f482d8edb3cbccfd10eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6089742183685303\n",
      "1.7753819227218628\n",
      "1.9056295156478882\n",
      "3.182711601257324\n",
      "4.899749279022217\n",
      "9.824283599853516\n",
      "13.753012657165527\n",
      "12.94542121887207\n",
      "15.444954872131348\n",
      "13.664255142211914\n",
      "27.199460983276367\n",
      "tensor(498.1331, device='cuda:0')\n",
      "13.01628303527832\n",
      "0.7589478492736816\n",
      "0.7383413910865784\n",
      "0.7628191709518433\n",
      "1.1560728549957275\n",
      "1.886223554611206\n",
      "4.403611660003662\n",
      "6.881244659423828\n",
      "5.656642436981201\n",
      "6.163177490234375\n",
      "5.7396769523620605\n",
      "12.028563499450684\n",
      "tensor(466.4814, device='cuda:0')\n",
      "5.59726095199585\n",
      "Rank 4 processed 10873 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f517ca0c684e37b96e510ed702dc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5818691253662109\n",
      "0.6097732782363892\n",
      "0.6290831565856934\n",
      "1.1899116039276123\n",
      "1.9739506244659424\n",
      "4.7065510749816895\n",
      "11.267168045043945\n",
      "10.901350021362305\n",
      "12.637166976928711\n",
      "12.264816284179688\n",
      "20.822343826293945\n",
      "tensor(543.0836, device='cuda:0')\n",
      "9.704038619995117\n",
      "1.7942392826080322\n",
      "1.7359626293182373\n",
      "1.737906813621521\n",
      "2.7516016960144043\n",
      "5.133839130401611\n",
      "12.380463600158691\n",
      "22.14581298828125\n",
      "17.784914016723633\n",
      "19.7203369140625\n",
      "17.943605422973633\n",
      "38.33359146118164\n",
      "tensor(476.6959, device='cuda:0')\n",
      "17.010986328125\n",
      "Rank 5 processed 15216 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72267d36a4744f1993c49777b3459c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7239408493041992\n",
      "0.7179388999938965\n",
      "0.7343124151229858\n",
      "1.1295394897460938\n",
      "2.0155153274536133\n",
      "5.037265300750732\n",
      "8.017084121704102\n",
      "8.442649841308594\n",
      "7.352766036987305\n",
      "7.356654167175293\n",
      "14.610427856445312\n",
      "tensor(509.0204, device='cuda:0')\n",
      "6.816707611083984\n",
      "1.500341534614563\n",
      "1.447311282157898\n",
      "1.4611836671829224\n",
      "1.8966397047042847\n",
      "3.020174264907837\n",
      "7.713567733764648\n",
      "10.155763626098633\n",
      "10.452178001403809\n",
      "10.41502571105957\n",
      "10.162291526794434\n",
      "21.336162567138672\n",
      "tensor(456.5302, device='cuda:0')\n",
      "10.178253173828125\n",
      "Rank 6 processed 9965 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0967d2c82d489da38abfa24e35cd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7167022824287415\n",
      "0.6953768730163574\n",
      "0.7535234689712524\n",
      "0.9724719524383545\n",
      "1.5181149244308472\n",
      "3.001340866088867\n",
      "4.311529159545898\n",
      "4.441833019256592\n",
      "4.870981693267822\n",
      "4.347212314605713\n",
      "8.693763732910156\n",
      "tensor(435.3042, device='cuda:0')\n",
      "4.289656639099121\n",
      "1.005161166191101\n",
      "1.2406340837478638\n",
      "1.616984486579895\n",
      "2.9154114723205566\n",
      "6.423720836639404\n",
      "12.452357292175293\n",
      "36.637298583984375\n",
      "30.42571258544922\n",
      "38.6875\n",
      "36.48271942138672\n",
      "68.35029602050781\n",
      "tensor(719.0798, device='cuda:0')\n",
      "32.68748092651367\n",
      "Rank 7 processed 11038 tokens.\n"
     ]
    }
   ],
   "source": [
    "eigenvalue_corrections = {}\n",
    "\n",
    "total_processed_global = 0\n",
    "for rank in range(workers):\n",
    "    eigenvalue_correction_test_path_rank = os.path.join(eigenvalue_correction_test_path, f\"rank_{rank}\")\n",
    "    os.makedirs(eigenvalue_correction_test_path_rank, exist_ok=True)\n",
    "\n",
    "    eigenvalue_corrections = {}\n",
    "    d = compute_eigenvalue_correction(\n",
    "        rank=rank,\n",
    "        eigenvalue_corrections=eigenvalue_corrections,\n",
    "        eigenvectors_activations=eigenvectors_activations,\n",
    "        eigenvectors_gradients=eigenvectors_gradients,\n",
    "    )\n",
    "    save_file(\n",
    "        eigenvalue_corrections, os.path.join(eigenvalue_correction_test_path_rank, \"eigenvalue_corrections.safetensors\")\n",
    "    )\n",
    "    with open(os.path.join(covariance_test_path_rank, \"stats.json\"), \"w\") as f:\n",
    "        json.dump({\"total_processed_rank\": d[\"total_processed_rank\"]}, f, indent=4)\n",
    "        print(f\"Rank {rank} processed {d['total_processed_rank']} tokens.\")\n",
    "    total_processed_global += d[\"total_processed_rank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results from all ranks\n",
    "eigenvalue_corrections = TensorDict({})\n",
    "\n",
    "\n",
    "for rank in range(workers):\n",
    "    eigenvalue_correction_test_path_rank = os.path.join(eigenvalue_correction_test_path, f\"rank_{rank}\")\n",
    "\n",
    "    # TensorDict wrapper to simplify tensor operations over dicts of tensors\n",
    "    eigenvalue_corrections_rank = TensorDict(\n",
    "        load_file(os.path.join(eigenvalue_correction_test_path_rank, \"eigenvalue_corrections.safetensors\"))\n",
    "    ).to(device)\n",
    "\n",
    "    if not eigenvalue_corrections:\n",
    "        eigenvalue_corrections = eigenvalue_corrections_rank\n",
    "    else:\n",
    "        eigenvalue_corrections = eigenvalue_corrections + (eigenvalue_corrections_rank)\n",
    "\n",
    "eigenvalue_corrections.div_(total_processed_global)\n",
    "save_file(\n",
    "    eigenvalue_corrections.to_dict(),\n",
    "    os.path.join(eigenvalue_correction_test_path, \"eigenvalue_corrections.safetensors\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "d_length = 10\n",
    "test_activations = {}\n",
    "test_gradients = {}\n",
    "batch_sizes = torch.randint(4000, 8000, (d_length,))\n",
    "activation_length = torch.randint(3000, 5000, (d_length,))\n",
    "gradient_length = torch.randint(3000, 10000, (d_length,))\n",
    "# Create test activations\n",
    "for i in range(d_length):\n",
    "    test_activations[f\"layer_{i}\"] = torch.rand(batch_sizes[i].item(), activation_length[i].item())\n",
    "    test_gradients[f\"layer_{i}\"] = torch.rand(batch_sizes[i].item(), gradient_length[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict({'layer_0': torch.Size([5658, 4830]), 'layer_1': torch.Size([6085, 3024]), 'layer_2': torch.Size([5339, 3124]), 'layer_3': torch.Size([6333, 3794]), 'layer_4': torch.Size([4273, 4821]), 'layer_5': torch.Size([5835, 4725]), 'layer_6': torch.Size([4997, 3745]), 'layer_7': torch.Size([5207, 3118]), 'layer_8': torch.Size([6180, 3869]), 'layer_9': torch.Size([5619, 3913])})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorDict(test_activations).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
