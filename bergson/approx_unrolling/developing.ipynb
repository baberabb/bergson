{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "from bergson.approx_unrolling.utils import TensorDict\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "\n",
    "model_str = \"EleutherAI/pythia-14m\"\n",
    "step = 5000\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "    model_str,\n",
    "    revision=f\"step{step}\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_str,\n",
    "    revision=f\"step{step}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exammining the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_comparison(path_1, path_2):\n",
    "    files_1 = os.listdir(path_1)\n",
    "    files_2 = os.listdir(path_2)\n",
    "\n",
    "    for file_1 in files_1:\n",
    "        if file_1 in files_2:\n",
    "            if file_1.endswith(\".safetensors\"):\n",
    "                tensor_1 = TensorDict(\n",
    "                    load_file(\n",
    "                        os.path.join(path_1, file_1),\n",
    "                        device=\"cuda\",\n",
    "                    )\n",
    "                )\n",
    "                tensor_2 = TensorDict(\n",
    "                    load_file(\n",
    "                        os.path.join(path_2, file_1),\n",
    "                        device=\"cuda\",\n",
    "                    )\n",
    "                )\n",
    "                diff = tensor_1 - tensor_2\n",
    "                all_close = tensor_1.allclose(tensor_2, rtol=1e-5, atol=1e-5)\n",
    "                all_close_values = all(all_close.values())\n",
    "                if not all_close_values:\n",
    "                    print(file_1)\n",
    "                    print(\"Differences found:\")\n",
    "                    print(diff.max())\n",
    "                # check if all_close has any key that is False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = \"/root/bergson/tests/caches/cache_1/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac_half\"\n",
    "path_2 = \"/root/bergson/tests/caches/cache_2/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac_half\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comparison(path_2, path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comparison(path_2, path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = TensorDict(load_file(os.path.join(path_1, \"gradient_covariance.safetensors\"), device=\"cuda\"))\n",
    "tensor_2 = TensorDict(load_file(os.path.join(path_2, \"gradient_covariance.safetensors\"), device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tensor_1 - tensor_2).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in (tensor_1 - tensor_2).items():\n",
    "    print(k, v.max().item(), v.min().item(), v.mean().item(), v.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = TensorDict(\n",
    "    load_file(\n",
    "        \"/root/bergson/bergson/approx_unrolling/.models/EleutherAI/pythia-14m/segment_0/influence_results/factors_ekfac_half/average_gradient_covariance.safetensors\",\n",
    "        device=\"cuda\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "d_2 = TensorDict(\n",
    "    load_file(\n",
    "        \"/root/bergson/.models/EleutherAI/influence_results/factors_ekfac_half/gradient_covariance.safetensors\",\n",
    "        device=\"cuda\",\n",
    "    )\n",
    ")\n",
    "\n",
    "diff = d - d_2\n",
    "\n",
    "for k, v in diff.items():\n",
    "    if v.max() < 1e-5:\n",
    "        continue\n",
    "    print(k)\n",
    "    print(v.max())\n",
    "    print(\"----\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 15335424\n",
    "# determine prime decomposition of number\n",
    "number / 7488\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bergson.approx_unrolling.utils import TensorDict\n",
    "\n",
    "\n",
    "d = TensorDict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [d, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/louis/bergson/bergson/approx_unrolling/influence_results/wikitext/factors_ekfac_half\"\n",
    "\n",
    "# list of all subfolders or files\n",
    "import os\n",
    "\n",
    "subfolders = []\n",
    "for dirpath, dirnames, filenames in os.walk(path):\n",
    "    for dirname in dirnames:\n",
    "        subfolders.append(os.path.join(dirpath, dirname))\n",
    "    for filename in filenames:\n",
    "        subfolders.append(os.path.join(dirpath, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames\n",
    "filenames_json = [f for f in subfolders if f.endswith(\".json\")]\n",
    "filesnames_safetensors = [f for f in subfolders if f.endswith(\".safetensors\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_file = filenames_json[0]\n",
    "with open(json_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesnames_safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "for i in range(len(filesnames_safetensors)):\n",
    "    path = filesnames_safetensors[i]\n",
    "    tensors = {}\n",
    "    with safe_open(path, framework=\"pt\", device=0) as f:\n",
    "        for k in f.keys():\n",
    "            tensors[k] = f.get_tensor(k)\n",
    "    print(tensors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = filesnames_safetensors[-2]\n",
    "with safe_open(path, framework=\"pt\", device=0) as f:\n",
    "    for k in f.keys():\n",
    "        tensors[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_2 = torch.load(\"/home/louis/bergson/bergson/approx_unrolling/checkpoints/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = model.state_dict()\n",
    "\n",
    "all_mlps = {k: v for k, v in all_weights.items() if \"mlp\" in k}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_mlps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_keys = [m[0] for m in model.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_attention = True\n",
    "track_mlp = True\n",
    "total_modules = []\n",
    "for m in module_keys:\n",
    "    if \"dropout\" in m.lower() or \"layernorm\" in m.lower():\n",
    "        continue\n",
    "\n",
    "    if \"attention\" in m.lower() and track_attention:\n",
    "        total_modules.append(m)\n",
    "    if \"mlp\" in m.lower() and track_mlp:\n",
    "        total_modules.append(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.wikitext.pipeline import get_wikitext_dataset\n",
    "\n",
    "train_dataset = get_wikitext_dataset(\n",
    "    split=\"eval_train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from train_dataset\n",
    "sample = train_dataset[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging kronfluence/bergson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_kronfluence = \"/root/quelle/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac\"\n",
    "activation_path = \"/root/quelle/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac/activation_covariance.safetensors\"\n",
    "gradient_path = \"/root/quelle/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac/gradient_covariance.safetensors\"\n",
    "\n",
    "path_sharded = \"/root/bergson-approx-unrolling/bergson/hessians/influence_results_sharded\"\n",
    "activation_path_sharded = (\n",
    "    \"/root/bergson-approx-unrolling/bergson/hessians/influence_results_sharded/activation_covariance.safetensors\"\n",
    ")\n",
    "gradient_path_sharded = (\n",
    "    \"/root/bergson-approx-unrolling/bergson/hessians/influence_results_sharded/gradient_covariance.safetensors\"\n",
    ")\n",
    "\n",
    "\n",
    "name = \"gpt_neox.layers.0.attention.dense\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_processed_path = (\n",
    "    \"/root/bergson-approx-unrolling/bergson/hessians/training_data/influence_results/total_processed.safetensors\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekfac_new_path = (\n",
    "    \"/root/bergson-approx-unrolling/bergson/hessians/training_data/influence_results/activation_covariance.safetensors\"\n",
    ")\n",
    "\n",
    "ekfac_new = TensorDict(load_file(ekfac_new_path, device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_processed = load_file(total_processed_path, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_processed': tensor(22343, device='cuda:0')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_path = \"/root/quelle/bergson/approx_unrolling/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac/num_gradient_covariance_processed.safetensors\"\n",
    "num_processed = TensorDict(load_file(num_path, device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict({'gpt_neox.layers.0.attention.dense': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.0.attention.query_key_value': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.0.mlp.dense_4h_to_h': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.0.mlp.dense_h_to_4h': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.1.attention.dense': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.1.attention.query_key_value': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.1.mlp.dense_4h_to_h': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.1.mlp.dense_h_to_4h': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.2.attention.dense': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.2.attention.query_key_value': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.2.mlp.dense_4h_to_h': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.2.mlp.dense_h_to_4h': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.3.attention.dense': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.3.attention.query_key_value': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.3.mlp.dense_4h_to_h': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.3.mlp.dense_h_to_4h': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.4.attention.dense': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.4.attention.query_key_value': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.4.mlp.dense_4h_to_h': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.4.mlp.dense_h_to_4h': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.5.attention.dense': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.5.attention.query_key_value': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.5.mlp.dense_4h_to_h': tensor([2439168], device='cuda:0'), 'gpt_neox.layers.5.mlp.dense_h_to_4h': tensor([2439168], device='cuda:0')})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "102400 / 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2439168"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(32 * 2048) * 37 + 7 * 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_kronfluence = TensorDict(load_file(activation_path, device=\"cuda\"))\n",
    "grad_kronfluence = TensorDict(load_file(gradient_path, device=\"cuda\"))\n",
    "act_sharded = TensorDict(load_file(activation_path_sharded, device=\"cuda\"))\n",
    "grad_sharded = TensorDict(load_file(gradient_path_sharded, device=\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_kronfluence.allclose(act_sharded, rtol=1e-5, atol=1).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_kronfluence.allclose(grad_sharded, rtol=1e-5, atol=1).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2048, 2048, device=\"cuda\").to(torch.bfloat16)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"linalg_eigh_cuda\" not implemented for 'BFloat16'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43meigh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: \"linalg_eigh_cuda\" not implemented for 'BFloat16'"
     ]
    }
   ],
   "source": [
    "torch.linalg.eigh(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging final algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/root/bergson-approx-unrolling/bergson/hessians/training_data/influence_results/gradient_eigen_sharded\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(path)\n",
    "tensors = []\n",
    "for file in files:\n",
    "    if file.endswith(\".safetensors\"):\n",
    "        tensor = TensorDict(load_file(os.path.join(path, file), device=\"cuda\"))\n",
    "        tensors.append(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tensors[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict({'layers.0.mlp.down_proj': torch.Size([448, 18944]), 'layers.0.mlp.gate_proj': torch.Size([0, 3584]), 'layers.0.mlp.up_proj': torch.Size([0, 3584]), 'layers.1.mlp.down_proj': torch.Size([448, 18944]), 'layers.1.mlp.gate_proj': torch.Size([0, 3584]), 'layers.1.mlp.up_proj': torch.Size([0, 3584]), 'layers.10.mlp.down_proj': torch.Size([448, 18944]), 'layers.10.mlp.gate_proj': torch.Size([0, 3584]), 'layers.10.mlp.up_proj': torch.Size([0, 3584]), 'layers.11.mlp.down_proj': torch.Size([448, 18944]), 'layers.11.mlp.gate_proj': torch.Size([0, 3584]), 'layers.11.mlp.up_proj': torch.Size([0, 3584]), 'layers.12.mlp.down_proj': torch.Size([448, 18944]), 'layers.12.mlp.gate_proj': torch.Size([0, 3584]), 'layers.12.mlp.up_proj': torch.Size([0, 3584]), 'layers.13.mlp.down_proj': torch.Size([448, 18944]), 'layers.13.mlp.gate_proj': torch.Size([0, 3584]), 'layers.13.mlp.up_proj': torch.Size([0, 3584]), 'layers.14.mlp.down_proj': torch.Size([448, 18944]), 'layers.14.mlp.gate_proj': torch.Size([0, 3584]), 'layers.14.mlp.up_proj': torch.Size([0, 3584]), 'layers.15.mlp.down_proj': torch.Size([448, 18944]), 'layers.15.mlp.gate_proj': torch.Size([0, 3584]), 'layers.15.mlp.up_proj': torch.Size([0, 3584]), 'layers.16.mlp.down_proj': torch.Size([448, 18944]), 'layers.16.mlp.gate_proj': torch.Size([0, 3584]), 'layers.16.mlp.up_proj': torch.Size([0, 3584]), 'layers.17.mlp.down_proj': torch.Size([448, 18944]), 'layers.17.mlp.gate_proj': torch.Size([0, 3584]), 'layers.17.mlp.up_proj': torch.Size([0, 3584]), 'layers.18.mlp.down_proj': torch.Size([448, 18944]), 'layers.18.mlp.gate_proj': torch.Size([0, 3584]), 'layers.18.mlp.up_proj': torch.Size([0, 3584]), 'layers.19.mlp.down_proj': torch.Size([448, 18944]), 'layers.19.mlp.gate_proj': torch.Size([0, 3584]), 'layers.19.mlp.up_proj': torch.Size([0, 3584]), 'layers.2.mlp.down_proj': torch.Size([448, 18944]), 'layers.2.mlp.gate_proj': torch.Size([0, 3584]), 'layers.2.mlp.up_proj': torch.Size([0, 3584]), 'layers.20.mlp.down_proj': torch.Size([448, 18944]), 'layers.20.mlp.gate_proj': torch.Size([0, 3584]), 'layers.20.mlp.up_proj': torch.Size([0, 3584]), 'layers.21.mlp.down_proj': torch.Size([448, 18944]), 'layers.21.mlp.gate_proj': torch.Size([0, 3584]), 'layers.21.mlp.up_proj': torch.Size([0, 3584]), 'layers.22.mlp.down_proj': torch.Size([448, 18944]), 'layers.22.mlp.gate_proj': torch.Size([0, 3584]), 'layers.22.mlp.up_proj': torch.Size([0, 3584]), 'layers.23.mlp.down_proj': torch.Size([448, 18944]), 'layers.23.mlp.gate_proj': torch.Size([0, 3584]), 'layers.23.mlp.up_proj': torch.Size([0, 3584]), 'layers.24.mlp.down_proj': torch.Size([448, 18944]), 'layers.24.mlp.gate_proj': torch.Size([0, 3584]), 'layers.24.mlp.up_proj': torch.Size([0, 3584]), 'layers.25.mlp.down_proj': torch.Size([448, 18944]), 'layers.25.mlp.gate_proj': torch.Size([0, 3584]), 'layers.25.mlp.up_proj': torch.Size([0, 3584]), 'layers.26.mlp.down_proj': torch.Size([448, 18944]), 'layers.26.mlp.gate_proj': torch.Size([0, 3584]), 'layers.26.mlp.up_proj': torch.Size([0, 3584]), 'layers.27.mlp.down_proj': torch.Size([448, 18944]), 'layers.27.mlp.gate_proj': torch.Size([0, 3584]), 'layers.27.mlp.up_proj': torch.Size([0, 3584]), 'layers.3.mlp.down_proj': torch.Size([448, 18944]), 'layers.3.mlp.gate_proj': torch.Size([0, 3584]), 'layers.3.mlp.up_proj': torch.Size([0, 3584]), 'layers.4.mlp.down_proj': torch.Size([448, 18944]), 'layers.4.mlp.gate_proj': torch.Size([0, 3584]), 'layers.4.mlp.up_proj': torch.Size([0, 3584]), 'layers.5.mlp.down_proj': torch.Size([448, 18944]), 'layers.5.mlp.gate_proj': torch.Size([0, 3584]), 'layers.5.mlp.up_proj': torch.Size([0, 3584]), 'layers.6.mlp.down_proj': torch.Size([448, 18944]), 'layers.6.mlp.gate_proj': torch.Size([0, 3584]), 'layers.6.mlp.up_proj': torch.Size([0, 3584]), 'layers.7.mlp.down_proj': torch.Size([448, 18944]), 'layers.7.mlp.gate_proj': torch.Size([0, 3584]), 'layers.7.mlp.up_proj': torch.Size([0, 3584]), 'layers.8.mlp.down_proj': torch.Size([448, 18944]), 'layers.8.mlp.gate_proj': torch.Size([0, 3584]), 'layers.8.mlp.up_proj': torch.Size([0, 3584]), 'layers.9.mlp.down_proj': torch.Size([448, 18944]), 'layers.9.mlp.gate_proj': torch.Size([0, 3584]), 'layers.9.mlp.up_proj': torch.Size([0, 3584])})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 8, 25\n",
    "batch = 1\n",
    "L = torch.nn.Linear(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.rand(batch, a)\n",
    "Ds = torch.rand(batch, b)\n",
    "prod = Ds.T @ v\n",
    "\n",
    "\n",
    "v_prime = torch.rand(batch, a)\n",
    "Ds_prime = torch.rand(batch, b)\n",
    "A = torch.outer(v_prime[0], v_prime[0])\n",
    "B = torch.outer(Ds_prime[0], Ds_prime[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = B @ prod @ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_Ds = B @ Ds.T\n",
    "transformed_v = v @ A\n",
    "transformed_prod = transformed_Ds @ transformed_v\n",
    "torch.allclose(final_result, transformed_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharded toy example\n",
    "A_1, A_2 = torch.chunk(A, 2, dim=0)\n",
    "B_1, B_2 = torch.chunk(B, 2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_1, v_2 = torch.chunk(v, 2, dim=1)\n",
    "Av_1, Av_2 = v_1 @ A_1, v_2 @ A_2\n",
    "Av = Av_1 + Av_2\n",
    "torch.allclose(Av, v @ A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_1, d_2 = B_1 @ Ds.T, B_2 @ Ds.T\n",
    "d = torch.cat([d_1, d_2], dim=0)\n",
    "torch.allclose(d, B @ Ds.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(final_result, d @ Av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
